---
layout: post
title: "9.2 최대가능도 추정법"
date: 2021-09-14 15:14:28 -0400
categories: [데이터 사이언스 수학]
tags: [확률론]
comments: true
math: true
---

### 가능도함수
- 확률분포 X에 대한 확률밀도함수 (또는 확률질량함수) 
    - $$p(x;\theta)$$
    - $$x$$: 확률분포가 가질 수 있는 실숫값
    - $$\theta$$:확률밀도함수의 모수를 표시
    - 두 값 모두 스칼라 혹은 벡터
- 확률분포가 베르누이 확률분포: $$\theta = \mu$$
- 확률분포가 이항분포: $$\theta = (N, \mu)$$
- 확률분포가 정규분포: $$\theta = (\mu, \sigma^2)$$
- 가능도 함수(likelihood function)
    - $$L(\theta;x)$$
    - 이미 알고있는 x를 상수계수로 놓고 $$\theta$$를 변수로 생각
    - $$L(\theta;x) = p(x;\theta)$$

### 최대가능도 추정법
- 최대가능도 추정법(Maximum Likelihood Estimation, MLE)
    - 주어진 표본에 대해 가능도를 가장 크게 하는 모수 $$\theta$$를 찾는 방법 
    - $$\hat \theta_{MLE} = \arg \max_{\theta} L(\theta;x)$$

### 복수의 표본 데이터가 있는 경우의 가능도함수
- 확률변수 표본의 수가 하나가 아니라 복수 개이므로 가능도함수도 복수 표본값에 대한 결합확률밀도가 됨
- 표본 데이터는 같은 확률분포에서 나온 독립적인 값들이므로 결합 확률밀도함수는 곱으로 표현됨
- $$L(\theta;x_1, \cdots, x_N) = p(x_1, \cdots, x_N; \theta) = \prod^N_{i=1} p(x_i;\theta)$$

### 로그가능도함수
- 일반적으로 최대가능도 추정법을 사용하여 가능도가 최대가 되는 $$\theta$$를 계산해려면 수치적 최적화(numerical optimization)를 해야 함
- 보통은 가능도를 직접 사용하는 것이 아니라 로그 변환한 로그가능도함수를 사용하는 경우가 많음
- $$\hat \theta_{ML} = \arg \max_{\theta} log L(\theta; {x_i})$$
- 로그 변환 이유
    - 로그 변환에 의해서 최대값의 위치가 변치 않음
    - 반복시행으로 인한 복수 표본 데이터인 경,우 결합 확률밀도함수가 동일한 함수의 곱으로 나타나는 경우가 많은데 이때 로그 변환에 의해 곱셈이 덧셈이 되어 계산이 단순해짐 

### 베르누이분포의 최대가능도 모수 추정
- 베르누이분포의 확률질량함수
    - $$p(x;\mu) = Bern(x;\mu) = \mu^x (1-\mu)^{1-x}$$
- 전체 확률질량함수
    - $$\prod^N_{i=1} \mu^{x_i}(1-\mu)^{1-x_i}$$
- 로그가능도    
    - $$log L = log p(x_1, \cdots, x_N;\mu)$$
    - $$\sum^N_{i=1} {x_i log \mu} + (N - \sum^N_{i=1} x_i) log(1-\mu)$$
    - ($$N_1 = \sum^N_{i=1} x_i, N_0 = N - \sum^N_{i=1} x_i$$ (x=1: 성공, x=0: 실패))
    - $$log L = N_1 log \mu + N_0 log(1-\mu)$$
    - 목적함수를 모수로 미분한 값이 0이 되게 하는 모숫값을 구하면
    - $$\mu = {N_1 \over N}$$
    - 즉, 최대가능도 추정법에 의한 베르누이분포의 모수는 1이 나온 횟수와 전체 시행횟수의 비율

### 카테고리분포의 최대가능도 모수 추정
- 카테고리분포의 확률질량함수
    - $$\prod^K_{k=1} \mu^{x_k}_k$$
    - $$\sum^K_{k=1} \mu_k = 1$$
    - x는 모두 k개의 원소를 가지는 원핫인코딩(one-hot-encoding)벡터
- 전체 확률밀도함수
    - N 번의 반복 시행으로 표본 데이터가 모두 독립이므로 전체 확률밀도함수는 각각의 확률질량함수의 곱과 같음
    - $$\prod^N_{i=1} \prod^K_{k=1} M^{x_{i,k}}_k$$ ($$x-{i,k}$$: i번째 시행 결과인 $$x_i$$의 k번째 원소)
- 로그가능도
    - $$log L = log p(x_1, \cdots, x_N; \mu_1, \cdots, \mu_K)$$
    - $$\sum^N_{i=1} \sum^K_{k=1} (x_{i,k} log \mu_k)$$
    - $$\sum^K_{k=1} \sum^N_{i=1} (log \mu_k \cdot x_{i,k})$$
    - $$\sum^K_{k=1} (log \mu_k (\sum^N_{i=1} (x_{i,k}))$$
    - $$N_k = \sum^N_{i=1} x_{i,k}$$  : k번째 원소가 나온 횟수
    - $$log L = \sum^K_{k=1}(log_{\mu_k} \cdot N_k)$$
    - 모수는 $$\sum^K_{k=1} \mu_k = 1$$를 만족해야 하므로
    - $$J = \sum^K_{k=1} log \mu_k N_k + \lambda(1- \sum^K_{k=1} \mu_k)$$ 를 모수로 미분한 값이 0이 되게 하는 모숫값을 구하면
    - $$\mu_k = {N_k \over N}$$
    - 최대가능도 추정법에 의한 카테고리분포의 모수는 각 범주값이 나온 횟수와 전체 시행횟수의 비율
    
### 정규분포의 최대가능도 모수 추정
- 

### 다변도정규분포의 최대 가능도 모수 추정


### 연습문제
- 9.2.1
- 9.2.2


<br/>
<br/>
이 글은 ['데이터 사이언스 스쿨 수학편'](https://datascienceschool.net/02%20mathematics/00.00%20소개의%20글.html)을 정리한 것입니다.
질문이나 오류가 있다면 댓글 남겨주세요.