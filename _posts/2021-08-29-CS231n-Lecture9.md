---
layout: post
title: "Stanford CS231n Lecture9 CNN Architectures"
date: 2021-08-28 23:37:28 -0400
categories: [Stanford CS231n]
tags: [DeepLearning, Stanford, CS231n, CNN]
comments: true
math: true
---

### LeNet-5
- ![1](/images/cs231n/lec9/1.png){: width="100%" height="100%"}
- early CNN model

### AlexNet
- ![2](/images/cs231n/lec9/2.png){: width="100%" height="100%"}
- input: 227 x 227 x 3 images (in the picture, it says 224, but 227 is correct)
- first layer (CONV 1): 96 11 x 11 filters, stride 4
    - output volume size: (227 - 11) / 4 + 1 = 55 $$\rightarrow$$ 96 x 55 x 55
    - total number of parameters: 11 x 11 x 3 x 96 = 35K
- second layer (POOL1): 3 x 3 filters, stride 2
    - output volume size: (55 - 3) / 2 + 1 = 27 $$\rightarrow$$ 96 x 27 x 27
    - total number of parameters: 0 (parameters are not required because only the largest values are selected in the pooling layer)
    - using two GPUs as a limit of memory when creating AlexNet, the output volume size is actually 2 x 48 x 27 x 27
- connections 
    - only with feature maps on same GPU: CONV1, CONV2, CONV4, CONV5
    - with all feature maps in preceding layer, communication across GPUs: CONV3, FC6, FC7, FC8
- details
    - first use of ReLU
    - used Norm layers (= Local Response Normalization)
        - ![10](/images/cs231n/lec9/10.png){: width="100%" height="100%"}
        - pixels in the same position at the activation map are normalized so that very large pixels do not affect the surroundings
        - not common anymore 
    - heavy data augmentation
    - dropout 0.5
    - batch size 128
    - SGD Momentum 0.9
    - Learning rate 1e-2, reduced by 10 manually when val accuracy plateaus
    - L2 weight decay 5e-4
    - 7 CNN ensemble
- performance
    - ![3](/images/cs231n/lec9/3.png){: width="100%" height="100%"} 

### ZFNet
- ![4](/images/cs231n/lec9/4.png){: width="100%" height="100%"}
- Based on AlexNet, (11x11 stride 4) was changed to (7x7 stride 2) at CONV1, and 512, 1024, and 512 filters were used instead of 384, 384, and 256 at CONV3, 4, 5.
- perforamnce
    - ![5](/images/cs231n/lec9/5.png){: width="100%" height="100%"}  

### VGGNet
- ![6](/images/cs231n/lec9/6.png){: width="70%" height="70%"}  
- small filters, deeper networks
    - 16- 19 layers
    - only 3 x 3 CONV stride 1, pad 1
    - only 2 x 2 MAX POOL stride 2
    - Q. Why use smaller filters? (3 x 3 CONV)
        - stack of 3 3 x 3 conv (stride 1) layers has same effective receptive field as 1 7 x 7 conv layer, but deeper, more non-linearities, and fewer parameters: $$3 \times 3^2 \times C^2$$ vs $$7^2 \times C^2 \ (C: input/output \ depth)$$
- ![7](/images/cs231n/lec9/7.png){: width="100%" height="100%"}
    - because the number of parameters has increased a lot compared to AlexNet and each image takes up 96MB, it is not easy to handle a lot of pictures
- details
    - ILSVRCâ€™14 2nd in classification, 1st in localization (localization: drawing a bounding box)
    - similar training procedure as AlexNet
    - no Local Response Normalisation
    - use VGG16 or VGG19 (VGG19 only slightly better, more memory, so VGG16 is more common)
    - use ensembles for best results
    - FC7 features generalize well to other tasks
    - ![8](/images/cs231n/lec9/8.png){: width="40%" height="100%"}
- performance
    - ![9](/images/cs231n/lec9/9.png){: width="100%" height="100%"}

### GoogLeNet
### ResNet
### Network in Network (NiN)
### Identity Mappings in Deep Residual Networks
### Wide Residual Networks
### Aggregated Residual Transformations for Deep Neural Networks (ResNeXt)
### Deep Networks with Stochastic Depth
### FractalNet: Ultra-Deep Neural Networks without Residuals
### Densely Connected Convolutional Networks
### SqueezeNet: AlexNet-level Accuracy With 50x Fewer Parameters and <0.5Mb Model Size
### Summary

<br/>
<br/>
This is written by me after taking CS231n Spring 2017 **provided by Stanford University**.
If you have questions, you can leave a reply on this post.