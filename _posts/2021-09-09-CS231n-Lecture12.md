---
layout: post
title: "Stanford CS231n Lecture12 Visualizing and Understanding"
date: 2021-09-09 16:02:28 -0400
categories: [Stanford CS231n]
tags: [DeepLearning, Stanford, CS231n, CNN]
comments: true
math: true
---

### Visualize Filters
- First Layer
    - ![1](/images/cs231n/lec12/1.png){: width="100%" height="100%"}
    - a feature map created after passing through the first layer of ConvNet
    - in the case of AlexNet, 64 3 x 11 x 11 feature maps are expressed in RGB
    - feature map varies depending on the characteristics of the filter
- Middle Layers
    - ![2](/images/cs231n/lec12/2.png){: width="100%" height="100%"}
    - visualize filters at higher layers, but not that interesting
    - since it continues to be calculated on the feature map, the deeper it becomes, the more difficult it becomes to grasp the information
- Last Layer
    - ![3](/images/cs231n/lec12/3.png){: width="50%" height="70%"}
    - layer immediately before the classifier
    - since feature vectors are collected, meaningful information can be obtained

<br/>
<br/>
This is written by me after taking CS231n Spring 2017 **provided by Stanford University**.
If you have questions, you can leave a reply on this post.