---
layout: post
title: "Stanford CS231n Lecture13 Generative Models"
date: 2021-09-30 15:05:28 -0400
categories: [Stanford CS231n]
tags: [DeepLearning, Stanford, CS231n, CNN]
comments: true
math: true
---

### Supervised vs Unsupervised Learning
- Supervised Learning
    - Data: (x, y) $$\rightarrow$$ x: data, y: label
    - Goal: learn a function to map x $$\rightarrow$$ y
    - Examples: classification, regression, object detection, semantic segmentation, image captioning, etc
- Unsupervised Learning
    - Data: data without label (training data is cheap)
    - Goal: learn some underlying hidden structure of the data
    - Examples: clustering, dimensionality reduction, feature learning, density estimation, etc

### Generative Models
- Given training data, generate new samples from same distribution
- ![1](/images/cs231n/lec13/1.png){: width="100%" height="100%"}
- Want to learn $$p_{model}(x)$$ similar to $$p_{data}(x)$$
- Ways
    - Explicit density estimation: explicitly define and solve for $$p_{model}(x)$$
    - Implicit density estimation: learn model that can sample from $$p_{model}(x)$$ w/o explicitly defining it 
- Why Generative Models?
    - Realistic samples for artwork, super-resolution, colorization, etc
    - Generative models of time-series data can be used for simulation and planning (reinforcement learning applications!)
    - Training generative models can also enable inference of latent representations that can be useful as general features (latent = hidden)
- ![2](/images/cs231n/lec13/2.png){: width="100%" height="100%"}

### PixelRNN and PixelCNN
- Explicit density model
- Use chain rule to decompose likelihood of an image x into product of 1-d distributions by a neural network (explicitly compute)
- $$p(x) = \prod^n_{i=1} p(x_i \vert x_1, \cdots, x_{i-1})$$ ($$p(x)$$: likelihood of image x, $$x_i$$: probability of iâ€™th pixel value given all previous pixels)
- maximize likelihood of training data
- explicit likelihood of training data gives good evaluation metric
- PixelRNN
    - ![3](/images/cs231n/lec13/3.png){: width="100%" height="100%"}
    - Generate image pixels starting from corner
    - Dependency on previous pixels modeled using an RNN (LSTM)
    - Drawback: sequential generation is very slow
- PixelCNN
    - ![4](/images/cs231n/lec13/4.png){: width="100%" height="100%"}
    - Generate image pixels starting from corner
    - Dependency on previous pixels modeled using a CNN over context region
    - Training: maximize likelihood of training images $$p(x)$$
    - Faster than PixelRNN, but still slow because it proceeds sequentially

### Variational Autoencoders (VAE)
- $$p_{\theta}(x) = \int p_{\theta}(z)p_{\theta}(x \vert z)dz$$
- Cannot optimize directly, derive and optimize lower bound on likelihood instead
- Background: Autoencder
    - ![5](/images/cs231n/lec13/5.png){: width="100%" height="100%"}
    - Unsupervised approach for learning a lower-dimensional feature representation from unlabeled training data
    - Encoder
        - Originally: Linear + nonlinearity (sigmoid)
        - Later: Deep, fully-connected
        - Later: ReLU CNN 
    - z usually smaller than x (dimensionality reduction, capture meaningful factors)
    - Decoder
        - Originally: Linear + nonlinearity (sigmoid)
        - Later: Deep, fully-connected
        - Later: ReLU CNN (upconv) 
    - ![6](/images/cs231n/lec13/6.png){: width="100%" height="100%"}
    - After training, throw away decoder
    - Encoder can be used to initialize a supervised model
- Variational Autoencoders
    - sample from the model to generate data
    - ![7](/images/cs231n/lec13/7.png){: width="100%" height="100%"}
    - How to represent the model
        - Choose prior p(z) to be simple, e.g. Gaussian
        - Conditional p(x|z) is complex (generates image), so represent with neural network
    - How to train the model
        - Learn model parameters to maximize likelihood of training data, but it is intractable
        - Data likelihood: $$p_{\theta}(x) = \int p_{\theta}(z)p_{\theta}(x \vert z)dz$$
            - $$p_{\theta}(z)$$: by simple Gaussian prior
            - $$p_{\theta}(x \vert z)$$: Decoder neural network
            - $$\int$$: Intractible to compute $$p(x \vert z)$$ for every z
        - Posterior density: $$p_{\theta}(z \vert x) = p_{\theta}(x \vert z)p_{\theta}(z)/p_{\theta}(x) \rightarrow p_{\theta}(x)$$: Intractable
        -  Solution: In addition to decoder network modeling $$p_{\theta}(x \vert z)$$, define additional encoder network $$q_{\phi}(z \vert x)$$ that approximates $$p_{\theta}(z \vert x)$$
            - ![8](/images/cs231n/lec13/8.png){: width="100%" height="100%"}
        - ![9](/images/cs231n/lec13/9.png){: width="100%" height="100%"}
        - $$E_z[ log p_{\theta} (x^{(i)} \vert z  ]$$: compute estimate through sampling
        - $$D_{KL}(q_{\phi}(z \vert x^{(i)}) \vert \vert p_{\theta}(z))$$: has closed-form solution
        - $$D_{KL}(q_{\phi}(z \vert x^{(i)}) \vert \vert p_{\theta}(z \vert x^{(i)}))$$: intractable $$\rightarrow p_{\theta}(z \vert x^{(i)})$$, but KL divergence always $$\geq 0$$
        - Think of the first two calculable terms ($$L(x^{(i)}, \theta, \phi)$$) as the lower bound and maximize them

### Generative Adversarial Networks (GAN)


<br/>
<br/>
This is written by me after taking CS231n Spring 2017 **provided by Stanford University**.
If you have questions, you can leave a reply on this post.